{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d292a3a86ec40809e9a4687c1144a15a",
     "grade": false,
     "grade_id": "cell-c6b7b8c7fbc1f9be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cross-Validation Lab and Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25aab398c80bfa7707a5ede5872a0893",
     "grade": false,
     "grade_id": "cell-d58d146c53b4e978",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This Lab and programming Assignment begins with the Boston Data set, in which we apply Linear, Ridge and Lasso Regression to the data, eventually using Cross-Validation.\n",
    "\n",
    "The Boston Data Set tells us the values of houses in different suburbs of Boston. It contains 506 observations and 14 features (columns). The last column/feature is the dependent variable `y`. Thus as a result we have 13 independent variables `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58b69e2fa320d927c64415a3b444e7e3",
     "grade": false,
     "grade_id": "cell-a03ef3b32d02fa4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set.seed(2021)\n",
    "library(MASS)    # Boston Data Set \n",
    "library(glmnet)  # Lasso and Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "752bd6af8fde15479529206cf25bd52e",
     "grade": false,
     "grade_id": "cell-30143ad73d4d8438",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n <- nrow(Boston)  # number of rows (n = 506)\n",
    "p <- ncol(Boston)  # number of columns (p = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "461fb49108c95ec9cb2e0b62af7f93da",
     "grade": false,
     "grade_id": "cell-bf91687dea15fece",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `sample` function allows us to randomly select 100 numbers from the vectors 1......n, without replacement, using the indices created, thus we can create the training and testing set. For the test set we specify the row number as the indices. For the train set we specify the row number as all the rows excluding for the indices. (add a minus sign that tells R that you would like to exclude the rows in the `test.index` factor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6521dc473d59ac694f095336ce1f66db",
     "grade": false,
     "grade_id": "cell-214b02c3240a2271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test.index <- sample(n, 100)  \n",
    "\n",
    "test  <- Boston[test.index,]     # test set \n",
    "train <- Boston[-test.index,]    # train set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6aa7e0d97274bd9505069c725bc3083",
     "grade": false,
     "grade_id": "cell-58b426c081eff504",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will now do a `linear regression`, `lasso regression` and `ridge regression`.\n",
    "\n",
    "For lasso, the first argument is the X-variables in the train set. The second argument is Y-variable in the train set. Remember, your last column is the y variable or the dependent variable, which is the medium value of houses in different suburbs in Boston. The rest of the 13 columns in the Boston Data set is your X-variable. Note that for the g`lmnet` function, your x-variable must be a matrix, hence the `as.matrix` function to convert the train set from a data frame to a matrix.\n",
    "\n",
    "We set `alpha  = 1` for lasso and if you want to run a ridge regression you set `alpha = 0`. Family argument is set to `gaussian` because we are doing a regression. For a classification problem, the family should be classified as `binomial` or `multinomial`.\n",
    "\n",
    "Lambda is set as 0.2 for both `lasso` and `ridge`. However, lambda value is user defined thus you can try whatever value you want, as long as it is a positive real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c17813221a607f41b49ce7dc1aa2ce79",
     "grade": false,
     "grade_id": "cell-9c1514237fdfb340",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear <-  lm(medv ~ . , data = train) # all 13 features/independent variables included here. \n",
    "lasso  <-  glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 1, family = \"gaussian\", lambda = 0.2) \n",
    "ridge  <-  glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 0, family = \"gaussian\", lambda = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `predict` function to do predictions. Simply input the model name that you have just saved and the the x-variables in your test set. Our x-variables are the first 13 columns of the test set.\n",
    "\n",
    "For the `glmnet` model, the x-variables need to be input as a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1175e95b3cbddf15d8dba022b5737fb2",
     "grade": false,
     "grade_id": "cell-c18522258069764c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pred.linear =  predict(linear, test[, 1:(p-1)])\n",
    "pred.lasso  =  predict(lasso, as.matrix(test[, 1:(p-1)]))\n",
    "pred.ridge  =  predict(ridge, as.matrix(test[, 1:(p-1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3301167bf80aea6eafe407479b72816",
     "grade": false,
     "grade_id": "cell-664e8972001e3796",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After you have done your predictions, go ahead and calculate the Sum of Squared Residuals (SSR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d5848f53a6c872bcc696eed5dc87c4",
     "grade": false,
     "grade_id": "cell-7b3c337ebb8ae8d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a85895fe346f5598a3d0229b2ee7b21",
     "grade": false,
     "grade_id": "cell-f02da9c265be83de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Calculate the SSR's for the Linear, Lasso and Ridge Regression. Use the output `SSR.linear`, `SSR.lasso` and `SSR.ridge` and the `sum` function to calculate the SSR's between `[test,[,p]` and pred.linear/pred.lasso/predict.ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cb32ae7c7f32c25423051251a2ad3d5",
     "grade": false,
     "grade_id": "cell-02017c805052d7c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "SSR.linear <- sum((test$medv - pred.linear) ^ 2)\n",
    "SSR.lasso  <-  sum((test$medv - pred.lasso) ^ 2)\n",
    "SSR.ridge  <-  sum((test$medv - pred.ridge) ^ 2)\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55d674b4e6d2ffe57894fcf0d38ee1bc",
     "grade": true,
     "grade_id": "cell-492c40397f5e751d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b758549995ecc066851a0742dec268a",
     "grade": false,
     "grade_id": "cell-8fcb81b625624e5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which model performs the best? Use the `cat` function to display the output from all three models. Comment on your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a510003baa6e9e1472f8f30457f759c0",
     "grade": false,
     "grade_id": "cell-0bbcb543252e9e6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3367.753 3525.683 3372.929"
     ]
    }
   ],
   "source": [
    "cat(SSR.linear, SSR.lasso, SSR.ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb3905c3f812aa3782e25ac411359d56",
     "grade": false,
     "grade_id": "cell-210a63fd93fd5f97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02161182495c0edf0f2a3fae3bdd4e7c",
     "grade": false,
     "grade_id": "cell-972842dc46623562",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can use *Cross-Validation* method to determine a good value for lambda. Using the `cv.glmnet` function, carry out the cross validation for `lasso` and `ridge` to determine the minimum `lambda` value. Use the outputs `lam.lasso` and `lam.ridge`. For the input values into the functions, it will be the same input used to carry out `lasso` and `ridge` with the `glmnet` function, i.e, for `lam.lasso`, along with the `as.matrix` function, your input should be  `(as.matrix(train[,1:(p-1)]), train[,p], alpha = 1, family = \"gaussian\")$lambda.min` and the same for `lam.ridge`, except this time your alpha value is going to be `zero`. \n",
    "\n",
    "The great advantage of the `cv.glment` function is that you don't need to input a range of values for lambda. The function can automatically locate a range of lambda values to test for you. Then you should save the best lambda value as `$lambda.min`. Then you do the lasso and ridge regression with the entire train set and the best lambda value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "525ccab2b363a19001cc78d92f37e60b",
     "grade": false,
     "grade_id": "cell-d5aa33a7bb7bb7fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.0176384402127719</li><li>0.679702337083701</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0176384402127719\n",
       "\\item 0.679702337083701\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0176384402127719\n",
       "2. 0.679702337083701\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.01763844 0.67970234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "lam.lasso <- cv.glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 1, family = \"gaussian\")$lambda.min\n",
    "lam.ridge <- cv.glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 0, family = \"gaussian\")$lambda.min\n",
    "\n",
    "c(lam.lasso, lam.ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ff1e9a5330d3ca31d904142caa898f0",
     "grade": true,
     "grade_id": "cell-f9ec71696288bd50",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a573fa7e245e2c1241ce6a11e07e74a3",
     "grade": false,
     "grade_id": "cell-399c5fdbee6b220f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83487ac080248326fdaf4ab35f10d832",
     "grade": false,
     "grade_id": "cell-afd74c75640cf4c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the lambda values from `lam.lasso` and `lam.ridgr` recalculate the `lasso` and `ridge` values. Again use the outputs `lasso` and `ridge`, the `glmnet` function and the `as.matrix` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24a30812ad7b4f4e42eb363d72da2b63",
     "grade": false,
     "grade_id": "cell-32b3ee23255b691c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "lasso  <-  glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 1, family = \"gaussian\", lambda = lam.lasso) \n",
    "ridge  <-  glmnet(as.matrix(train[, 1:(p-1)]), train[,p], alpha = 0, family = \"gaussian\", lambda = lam.ridge)\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79a35a49b37e8f3b9a87e181b3f6a0ed",
     "grade": true,
     "grade_id": "cell-11a03d4a10872c9f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f5662b84848c9a788e1c8477dec62a",
     "grade": false,
     "grade_id": "cell-cb18c2301c537b5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc282ca67e3bf5929d0afe47eacff45",
     "grade": false,
     "grade_id": "cell-07becea358432233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recalculate `pred.linear`, `pred.lasso` and `pred.ridge` using the same outputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62bf6282b9ec371a39717fd4dbb5532c",
     "grade": false,
     "grade_id": "cell-ccef451b14aa5c2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "pred.linear =  predict(linear, test[, 1:(p-1)])\n",
    "pred.lasso  =  predict(lasso, as.matrix(test[, 1:(p-1)]))\n",
    "pred.ridge  =  predict(ridge, as.matrix(test[, 1:(p-1)]))\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05244e583a6382f38745c3587c6b7890",
     "grade": true,
     "grade_id": "cell-b205b12d11045d3e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b8d6f41af32084aa05f8ecbf80bc549",
     "grade": false,
     "grade_id": "cell-32fa33aabb6ca944",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "083535e82e1d16a7533e81d29fb9cee7",
     "grade": false,
     "grade_id": "cell-302e747503ab6b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recalculate the SSR's (sum of squared residuals) for the Linear, Lasso and Ridge Regression. Use the output `SSR.linear`, `SSR.lasso` and `SSR.ridge` and the `sum` function to calculate the SSR's between `[test,[,p]` and pred.linear/pred.lasso/predict.ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "912ee738ad002b0d654259fd85f3deaf",
     "grade": false,
     "grade_id": "cell-7f9878cbe1528c84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "SSR.linear <- sum((test$medv - pred.linear) ^ 2)\n",
    "SSR.lasso  <-  sum((test$medv - pred.lasso) ^ 2)\n",
    "SSR.ridge  <-  sum((test$medv - pred.ridge) ^ 2)\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d7451aef049d0dcaec3d2167a9458ac",
     "grade": true,
     "grade_id": "cell-da3d4a54a3ba85b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e16ba4d29ed6d538a2d4b0a398e9250",
     "grade": false,
     "grade_id": "cell-f776a11cf1458fc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which model performs the best? Use the `cat` function to display the output from all three models. Comment on your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c9bce299730dc2b1a15dee4a8761a33",
     "grade": false,
     "grade_id": "cell-1f698e595d210e9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3367.753 3367.76 3432.617"
     ]
    }
   ],
   "source": [
    "cat(SSR.linear, SSR.lasso, SSR.ridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
