{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d19c30bd6fdf397dd34c68c8987828a6",
     "grade": false,
     "grade_id": "cell-fa8c9f208dc55e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca98e0fe65c308246844cec0f2fda61e",
     "grade": false,
     "grade_id": "cell-38f655eda540f8f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This programming assignment will use the `Tidy Models` platform. It will take a look at regularization models and hyperparameter tuning. These models contain a regularization term. This assignment will use [parsnip](https://www.tidymodels.org/start/models/) for model fitting and [recipes and workflows](https://www.tidymodels.org/start/recipes/) to perform the transformations, and [tune and dials](https://www.tidymodels.org/start/tuning/) to tune the hyperparameters of the model.\n",
    "\n",
    "You will be using the `Hitters` data set from the `ISLR` package. You wish to predict the baseball players `Salary` based on several different characteristics which are included in the data set. \n",
    "\n",
    "Since you wish to predict `Salary`, then you need to remove any missing data from that column. Otherwise, you won't be able to run the models.\n",
    "\n",
    "**Set output as** `Hitters` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6f81d6cb6df6250f11f5a3d2fe06a20",
     "grade": false,
     "grade_id": "cell-1e513d03cb81c849",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mtibble      \u001b[39m 3.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2     \u001b[39m 3.4.1     \u001b[32m✔\u001b[39m \u001b[34mtidyr       \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr       \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mscales\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m  masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidymodels)\n",
    "library(ISLR2)\n",
    "\n",
    "Hitters <- as_tibble(Hitters) %>%\n",
    "  filter(!is.na(Salary))\n",
    "\n",
    "Hitters_split <- initial_split(Hitters, strata = \"Salary\")\n",
    "Hitters_train <- training(Hitters_split)\n",
    "Hitters_test <- testing(Hitters_split)\n",
    "Hitters_fold <- vfold_cv(Hitters_train, v = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0c037eec3831b9b8c6ab60b98f5d0ae",
     "grade": true,
     "grade_id": "cell-fe6741d03449f940",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f09d269c304bdee35c88691e0fd7d13f",
     "grade": false,
     "grade_id": "cell-91f32cd77f321169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You will use the `glmnet` package to perform **ridge regression**. `parsnip` does not have a dedicated function to create a ridge regression model specification. You need to use `linear_reg()` and set `mixture = 0` to specify a ridge model. The `mixture` argument specifies the amount of different types of regularization, `mixture = 0` specifies only **ridge regularization** and `mixture = 1` specifies only **lasso regularization**. \n",
    "\n",
    "Setting `mixture` to a value between 0 and 1 lets us use both. When using the `glmnet` engine you also need to set a `penalty` to be able to fit the model. You will set this value to `0` for now, it is not the best value, but you will look at how to select the best value in a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e65b417c0080e0df5b990e4f6c4fafa",
     "grade": false,
     "grade_id": "cell-b41afcc7f31ef514",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ridge_spec <- linear_reg(mixture = 0, penalty = 0) %>%\n",
    "  set_mode(\"regression\") %>%\n",
    "  set_engine(\"glmnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80cb930431a89b809905790a6cb69263",
     "grade": false,
     "grade_id": "cell-b2e05310215cfafd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once the specification is created you can fit it to you data. You will use all the predictors. Use the `fit` function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1b90a3f8716e7732f486b48225bac7e",
     "grade": false,
     "grade_id": "cell-2621b9ede340e901",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ridge_fit <- fit(ridge_spec, Salary ~ ., data = Hitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4faa5026f54c88774fe3e6cfb858b88",
     "grade": false,
     "grade_id": "cell-92d0498c27a88c40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `glmnet` package will fit the model for all values of `penalty` at once, so you can now see see what the parameter estimate for the model is now that you have `penalty = 0`. You can use the `tidy` function to accomplish this specific  task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4f40075178b5fb0908717e4973e86c4",
     "grade": false,
     "grade_id": "cell-312ddae5ace72440",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:tidyr’:\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n",
      "\n",
      "Loaded glmnet 4.1-6\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 20 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>penalty</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>(Intercept)</td><td> 8.112693e+01</td><td>0</td></tr>\n",
       "\t<tr><td>AtBat      </td><td>-6.815959e-01</td><td>0</td></tr>\n",
       "\t<tr><td>Hits       </td><td> 2.772312e+00</td><td>0</td></tr>\n",
       "\t<tr><td>HmRun      </td><td>-1.365680e+00</td><td>0</td></tr>\n",
       "\t<tr><td>Runs       </td><td> 1.014826e+00</td><td>0</td></tr>\n",
       "\t<tr><td>RBI        </td><td> 7.130224e-01</td><td>0</td></tr>\n",
       "\t<tr><td>Walks      </td><td> 3.378558e+00</td><td>0</td></tr>\n",
       "\t<tr><td>Years      </td><td>-9.066800e+00</td><td>0</td></tr>\n",
       "\t<tr><td>CAtBat     </td><td>-1.199478e-03</td><td>0</td></tr>\n",
       "\t<tr><td>CHits      </td><td> 1.361029e-01</td><td>0</td></tr>\n",
       "\t<tr><td>CHmRun     </td><td> 6.979958e-01</td><td>0</td></tr>\n",
       "\t<tr><td>CRuns      </td><td> 2.958896e-01</td><td>0</td></tr>\n",
       "\t<tr><td>CRBI       </td><td> 2.570711e-01</td><td>0</td></tr>\n",
       "\t<tr><td>CWalks     </td><td>-2.789666e-01</td><td>0</td></tr>\n",
       "\t<tr><td>LeagueN    </td><td> 5.321272e+01</td><td>0</td></tr>\n",
       "\t<tr><td>DivisionW  </td><td>-1.228345e+02</td><td>0</td></tr>\n",
       "\t<tr><td>PutOuts    </td><td> 2.638876e-01</td><td>0</td></tr>\n",
       "\t<tr><td>Assists    </td><td> 1.698796e-01</td><td>0</td></tr>\n",
       "\t<tr><td>Errors     </td><td>-3.685645e+00</td><td>0</td></tr>\n",
       "\t<tr><td>NewLeagueN </td><td>-1.810510e+01</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 20 × 3\n",
       "\\begin{tabular}{lll}\n",
       " term & estimate & penalty\\\\\n",
       " <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t (Intercept) &  8.112693e+01 & 0\\\\\n",
       "\t AtBat       & -6.815959e-01 & 0\\\\\n",
       "\t Hits        &  2.772312e+00 & 0\\\\\n",
       "\t HmRun       & -1.365680e+00 & 0\\\\\n",
       "\t Runs        &  1.014826e+00 & 0\\\\\n",
       "\t RBI         &  7.130224e-01 & 0\\\\\n",
       "\t Walks       &  3.378558e+00 & 0\\\\\n",
       "\t Years       & -9.066800e+00 & 0\\\\\n",
       "\t CAtBat      & -1.199478e-03 & 0\\\\\n",
       "\t CHits       &  1.361029e-01 & 0\\\\\n",
       "\t CHmRun      &  6.979958e-01 & 0\\\\\n",
       "\t CRuns       &  2.958896e-01 & 0\\\\\n",
       "\t CRBI        &  2.570711e-01 & 0\\\\\n",
       "\t CWalks      & -2.789666e-01 & 0\\\\\n",
       "\t LeagueN     &  5.321272e+01 & 0\\\\\n",
       "\t DivisionW   & -1.228345e+02 & 0\\\\\n",
       "\t PutOuts     &  2.638876e-01 & 0\\\\\n",
       "\t Assists     &  1.698796e-01 & 0\\\\\n",
       "\t Errors      & -3.685645e+00 & 0\\\\\n",
       "\t NewLeagueN  & -1.810510e+01 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 20 × 3\n",
       "\n",
       "| term &lt;chr&gt; | estimate &lt;dbl&gt; | penalty &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| (Intercept) |  8.112693e+01 | 0 |\n",
       "| AtBat       | -6.815959e-01 | 0 |\n",
       "| Hits        |  2.772312e+00 | 0 |\n",
       "| HmRun       | -1.365680e+00 | 0 |\n",
       "| Runs        |  1.014826e+00 | 0 |\n",
       "| RBI         |  7.130224e-01 | 0 |\n",
       "| Walks       |  3.378558e+00 | 0 |\n",
       "| Years       | -9.066800e+00 | 0 |\n",
       "| CAtBat      | -1.199478e-03 | 0 |\n",
       "| CHits       |  1.361029e-01 | 0 |\n",
       "| CHmRun      |  6.979958e-01 | 0 |\n",
       "| CRuns       |  2.958896e-01 | 0 |\n",
       "| CRBI        |  2.570711e-01 | 0 |\n",
       "| CWalks      | -2.789666e-01 | 0 |\n",
       "| LeagueN     |  5.321272e+01 | 0 |\n",
       "| DivisionW   | -1.228345e+02 | 0 |\n",
       "| PutOuts     |  2.638876e-01 | 0 |\n",
       "| Assists     |  1.698796e-01 | 0 |\n",
       "| Errors      | -3.685645e+00 | 0 |\n",
       "| NewLeagueN  | -1.810510e+01 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "   term        estimate      penalty\n",
       "1  (Intercept)  8.112693e+01 0      \n",
       "2  AtBat       -6.815959e-01 0      \n",
       "3  Hits         2.772312e+00 0      \n",
       "4  HmRun       -1.365680e+00 0      \n",
       "5  Runs         1.014826e+00 0      \n",
       "6  RBI          7.130224e-01 0      \n",
       "7  Walks        3.378558e+00 0      \n",
       "8  Years       -9.066800e+00 0      \n",
       "9  CAtBat      -1.199478e-03 0      \n",
       "10 CHits        1.361029e-01 0      \n",
       "11 CHmRun       6.979958e-01 0      \n",
       "12 CRuns        2.958896e-01 0      \n",
       "13 CRBI         2.570711e-01 0      \n",
       "14 CWalks      -2.789666e-01 0      \n",
       "15 LeagueN      5.321272e+01 0      \n",
       "16 DivisionW   -1.228345e+02 0      \n",
       "17 PutOuts      2.638876e-01 0      \n",
       "18 Assists      1.698796e-01 0      \n",
       "19 Errors      -3.685645e+00 0      \n",
       "20 NewLeagueN  -1.810510e+01 0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tidy(ridge_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9466edac9cb87b1b52d22837775fcd48",
     "grade": false,
     "grade_id": "cell-5724b06e76e61415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us instead see what the estimates would be if the penalty was `11498`. Store your output to `tidy2`. What do you notice?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9463ee8dcc32bda2181da2ada40ff270",
     "grade": false,
     "grade_id": "cell-99ef8a325d97edf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "tidy2 <- tidy(ridge_fit, penalty = 11498)\n",
    "\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59ee543c7e45438f5fa9f977d03e9682",
     "grade": true,
     "grade_id": "cell-8e05b242ee24117f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90ace8a3d8bb7a02fbde4935c1daa206",
     "grade": false,
     "grade_id": "cell-2d04cd1be838c4e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Look below at the parameter estimates for `penalty = 705`. Store your output to `tidy3`. Once again, use the `tidy` function to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26553114e0dd128f714c064904d27d20",
     "grade": false,
     "grade_id": "cell-4b7ba595bbd14b35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "tidy3 <- tidy(ridge_fit, penalty = 705)\n",
    "\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a397db0877bc9a717079ea03a98fb4a5",
     "grade": true,
     "grade_id": "cell-3466a2b46607f649",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "attachments": {
    "output%20image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a774a51489aa194c3071fa8d4b85423b",
     "grade": false,
     "grade_id": "cell-41307fcbc0f4b0ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can visualize how the magnitude of the coefficients are being regularized towards zero as the penalty goes up. Use the `autoplot()` function to accomplish this task. **Output variable here is** `ridge_fit`. Your image should look like this: \n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:output%20image.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d2fb963a999ffcde1cc7081da70628c",
     "grade": false,
     "grade_id": "cell-3ad640c9f1191763",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:14: unexpected SPECIAL\n1: ridge_fit <- %>%\n                 ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:14: unexpected SPECIAL\n1: ridge_fit <- %>%\n                 ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "ridge_fit <- %>% autoplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da1c3c3e918b602b11c74b0a24b9a9e1",
     "grade": false,
     "grade_id": "cell-26bf1c32da3c98ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Prediction is done like normal, if you use `predict()` by itself, then `penalty = 0` as you set in the model specification is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39cfcd8b401d1ac21b396950d3d73376",
     "grade": false,
     "grade_id": "cell-00a050726bdf5a89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 263 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.pred</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 441.66554</td></tr>\n",
       "\t<tr><td> 675.58136</td></tr>\n",
       "\t<tr><td>1058.51428</td></tr>\n",
       "\t<tr><td> 520.67640</td></tr>\n",
       "\t<tr><td> 542.92917</td></tr>\n",
       "\t<tr><td> 217.79896</td></tr>\n",
       "\t<tr><td>  74.69312</td></tr>\n",
       "\t<tr><td>  96.13955</td></tr>\n",
       "\t<tr><td> 808.99002</td></tr>\n",
       "\t<tr><td> 865.39782</td></tr>\n",
       "\t<tr><td> 235.62205</td></tr>\n",
       "\t<tr><td> 509.95152</td></tr>\n",
       "\t<tr><td> 308.28644</td></tr>\n",
       "\t<tr><td> 376.67998</td></tr>\n",
       "\t<tr><td>1095.01340</td></tr>\n",
       "\t<tr><td>  18.06719</td></tr>\n",
       "\t<tr><td> 106.64712</td></tr>\n",
       "\t<tr><td> 481.46312</td></tr>\n",
       "\t<tr><td> 352.87140</td></tr>\n",
       "\t<tr><td> 587.30412</td></tr>\n",
       "\t<tr><td>1370.37657</td></tr>\n",
       "\t<tr><td> 747.83286</td></tr>\n",
       "\t<tr><td> 333.75660</td></tr>\n",
       "\t<tr><td> 541.32277</td></tr>\n",
       "\t<tr><td> 615.70456</td></tr>\n",
       "\t<tr><td> 851.05093</td></tr>\n",
       "\t<tr><td> 225.72717</td></tr>\n",
       "\t<tr><td> 568.24050</td></tr>\n",
       "\t<tr><td> 177.09202</td></tr>\n",
       "\t<tr><td> 685.65534</td></tr>\n",
       "\t<tr><td>⋮</td></tr>\n",
       "\t<tr><td> 626.6399</td></tr>\n",
       "\t<tr><td> 407.2584</td></tr>\n",
       "\t<tr><td> 325.9571</td></tr>\n",
       "\t<tr><td> 710.3232</td></tr>\n",
       "\t<tr><td> 217.8419</td></tr>\n",
       "\t<tr><td> 760.2085</td></tr>\n",
       "\t<tr><td> 118.1205</td></tr>\n",
       "\t<tr><td> 174.0792</td></tr>\n",
       "\t<tr><td> 239.3390</td></tr>\n",
       "\t<tr><td> 181.8702</td></tr>\n",
       "\t<tr><td> 317.0220</td></tr>\n",
       "\t<tr><td> 818.1938</td></tr>\n",
       "\t<tr><td> 427.4666</td></tr>\n",
       "\t<tr><td> 456.6732</td></tr>\n",
       "\t<tr><td> 335.6825</td></tr>\n",
       "\t<tr><td> 829.3222</td></tr>\n",
       "\t<tr><td> 388.2350</td></tr>\n",
       "\t<tr><td> 589.0304</td></tr>\n",
       "\t<tr><td> 529.1102</td></tr>\n",
       "\t<tr><td>1124.2869</td></tr>\n",
       "\t<tr><td> 484.0255</td></tr>\n",
       "\t<tr><td> 505.3788</td></tr>\n",
       "\t<tr><td> 983.4427</td></tr>\n",
       "\t<tr><td> 490.6313</td></tr>\n",
       "\t<tr><td> 701.8502</td></tr>\n",
       "\t<tr><td> 658.4885</td></tr>\n",
       "\t<tr><td> 874.6757</td></tr>\n",
       "\t<tr><td> 305.9239</td></tr>\n",
       "\t<tr><td>1057.2345</td></tr>\n",
       "\t<tr><td> 663.9920</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 263 × 1\n",
       "\\begin{tabular}{l}\n",
       " .pred\\\\\n",
       " <dbl>\\\\\n",
       "\\hline\n",
       "\t  441.66554\\\\\n",
       "\t  675.58136\\\\\n",
       "\t 1058.51428\\\\\n",
       "\t  520.67640\\\\\n",
       "\t  542.92917\\\\\n",
       "\t  217.79896\\\\\n",
       "\t   74.69312\\\\\n",
       "\t   96.13955\\\\\n",
       "\t  808.99002\\\\\n",
       "\t  865.39782\\\\\n",
       "\t  235.62205\\\\\n",
       "\t  509.95152\\\\\n",
       "\t  308.28644\\\\\n",
       "\t  376.67998\\\\\n",
       "\t 1095.01340\\\\\n",
       "\t   18.06719\\\\\n",
       "\t  106.64712\\\\\n",
       "\t  481.46312\\\\\n",
       "\t  352.87140\\\\\n",
       "\t  587.30412\\\\\n",
       "\t 1370.37657\\\\\n",
       "\t  747.83286\\\\\n",
       "\t  333.75660\\\\\n",
       "\t  541.32277\\\\\n",
       "\t  615.70456\\\\\n",
       "\t  851.05093\\\\\n",
       "\t  225.72717\\\\\n",
       "\t  568.24050\\\\\n",
       "\t  177.09202\\\\\n",
       "\t  685.65534\\\\\n",
       "\t ⋮\\\\\n",
       "\t  626.6399\\\\\n",
       "\t  407.2584\\\\\n",
       "\t  325.9571\\\\\n",
       "\t  710.3232\\\\\n",
       "\t  217.8419\\\\\n",
       "\t  760.2085\\\\\n",
       "\t  118.1205\\\\\n",
       "\t  174.0792\\\\\n",
       "\t  239.3390\\\\\n",
       "\t  181.8702\\\\\n",
       "\t  317.0220\\\\\n",
       "\t  818.1938\\\\\n",
       "\t  427.4666\\\\\n",
       "\t  456.6732\\\\\n",
       "\t  335.6825\\\\\n",
       "\t  829.3222\\\\\n",
       "\t  388.2350\\\\\n",
       "\t  589.0304\\\\\n",
       "\t  529.1102\\\\\n",
       "\t 1124.2869\\\\\n",
       "\t  484.0255\\\\\n",
       "\t  505.3788\\\\\n",
       "\t  983.4427\\\\\n",
       "\t  490.6313\\\\\n",
       "\t  701.8502\\\\\n",
       "\t  658.4885\\\\\n",
       "\t  874.6757\\\\\n",
       "\t  305.9239\\\\\n",
       "\t 1057.2345\\\\\n",
       "\t  663.9920\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 263 × 1\n",
       "\n",
       "| .pred &lt;dbl&gt; |\n",
       "|---|\n",
       "|  441.66554 |\n",
       "|  675.58136 |\n",
       "| 1058.51428 |\n",
       "|  520.67640 |\n",
       "|  542.92917 |\n",
       "|  217.79896 |\n",
       "|   74.69312 |\n",
       "|   96.13955 |\n",
       "|  808.99002 |\n",
       "|  865.39782 |\n",
       "|  235.62205 |\n",
       "|  509.95152 |\n",
       "|  308.28644 |\n",
       "|  376.67998 |\n",
       "| 1095.01340 |\n",
       "|   18.06719 |\n",
       "|  106.64712 |\n",
       "|  481.46312 |\n",
       "|  352.87140 |\n",
       "|  587.30412 |\n",
       "| 1370.37657 |\n",
       "|  747.83286 |\n",
       "|  333.75660 |\n",
       "|  541.32277 |\n",
       "|  615.70456 |\n",
       "|  851.05093 |\n",
       "|  225.72717 |\n",
       "|  568.24050 |\n",
       "|  177.09202 |\n",
       "|  685.65534 |\n",
       "| ⋮ |\n",
       "|  626.6399 |\n",
       "|  407.2584 |\n",
       "|  325.9571 |\n",
       "|  710.3232 |\n",
       "|  217.8419 |\n",
       "|  760.2085 |\n",
       "|  118.1205 |\n",
       "|  174.0792 |\n",
       "|  239.3390 |\n",
       "|  181.8702 |\n",
       "|  317.0220 |\n",
       "|  818.1938 |\n",
       "|  427.4666 |\n",
       "|  456.6732 |\n",
       "|  335.6825 |\n",
       "|  829.3222 |\n",
       "|  388.2350 |\n",
       "|  589.0304 |\n",
       "|  529.1102 |\n",
       "| 1124.2869 |\n",
       "|  484.0255 |\n",
       "|  505.3788 |\n",
       "|  983.4427 |\n",
       "|  490.6313 |\n",
       "|  701.8502 |\n",
       "|  658.4885 |\n",
       "|  874.6757 |\n",
       "|  305.9239 |\n",
       "| 1057.2345 |\n",
       "|  663.9920 |\n",
       "\n"
      ],
      "text/plain": [
       "    .pred     \n",
       "1    441.66554\n",
       "2    675.58136\n",
       "3   1058.51428\n",
       "4    520.67640\n",
       "5    542.92917\n",
       "6    217.79896\n",
       "7     74.69312\n",
       "8     96.13955\n",
       "9    808.99002\n",
       "10   865.39782\n",
       "11   235.62205\n",
       "12   509.95152\n",
       "13   308.28644\n",
       "14   376.67998\n",
       "15  1095.01340\n",
       "16    18.06719\n",
       "17   106.64712\n",
       "18   481.46312\n",
       "19   352.87140\n",
       "20   587.30412\n",
       "21  1370.37657\n",
       "22   747.83286\n",
       "23   333.75660\n",
       "24   541.32277\n",
       "25   615.70456\n",
       "26   851.05093\n",
       "27   225.72717\n",
       "28   568.24050\n",
       "29   177.09202\n",
       "30   685.65534\n",
       "⋮   ⋮         \n",
       "234  626.6399 \n",
       "235  407.2584 \n",
       "236  325.9571 \n",
       "237  710.3232 \n",
       "238  217.8419 \n",
       "239  760.2085 \n",
       "240  118.1205 \n",
       "241  174.0792 \n",
       "242  239.3390 \n",
       "243  181.8702 \n",
       "244  317.0220 \n",
       "245  818.1938 \n",
       "246  427.4666 \n",
       "247  456.6732 \n",
       "248  335.6825 \n",
       "249  829.3222 \n",
       "250  388.2350 \n",
       "251  589.0304 \n",
       "252  529.1102 \n",
       "253 1124.2869 \n",
       "254  484.0255 \n",
       "255  505.3788 \n",
       "256  983.4427 \n",
       "257  490.6313 \n",
       "258  701.8502 \n",
       "259  658.4885 \n",
       "260  874.6757 \n",
       "261  305.9239 \n",
       "262 1057.2345 \n",
       "263  663.9920 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(ridge_fit, new_data = Hitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc5e83512d60207195b6f61da16a9483",
     "grade": false,
     "grade_id": "cell-2f2aeb4aa706819f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "But you can also get predictions for other values of `penalty` by specifying it in `predict()`. Test with a value of `500`. Store your output to `predict_500`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "183aa6195ffd9afed309e7e354e4ce79",
     "grade": false,
     "grade_id": "cell-ec04351caf3d6022",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.pred</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>525.3820</td></tr>\n",
       "\t<tr><td>620.1190</td></tr>\n",
       "\t<tr><td>894.5125</td></tr>\n",
       "\t<tr><td>424.7725</td></tr>\n",
       "\t<tr><td>588.5251</td></tr>\n",
       "\t<tr><td>178.5795</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 1\n",
       "\\begin{tabular}{l}\n",
       " .pred\\\\\n",
       " <dbl>\\\\\n",
       "\\hline\n",
       "\t 525.3820\\\\\n",
       "\t 620.1190\\\\\n",
       "\t 894.5125\\\\\n",
       "\t 424.7725\\\\\n",
       "\t 588.5251\\\\\n",
       "\t 178.5795\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 1\n",
       "\n",
       "| .pred &lt;dbl&gt; |\n",
       "|---|\n",
       "| 525.3820 |\n",
       "| 620.1190 |\n",
       "| 894.5125 |\n",
       "| 424.7725 |\n",
       "| 588.5251 |\n",
       "| 178.5795 |\n",
       "\n"
      ],
      "text/plain": [
       "  .pred   \n",
       "1 525.3820\n",
       "2 620.1190\n",
       "3 894.5125\n",
       "4 424.7725\n",
       "5 588.5251\n",
       "6 178.5795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "\n",
    "predict_500 <- predict(ridge_fit, penalty = 500, new_data = Hitters)\n",
    "\n",
    "head(predict_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64e632c8b5992804aad59908c5e349e7",
     "grade": true,
     "grade_id": "cell-418da39ec39c889d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e70cf2016aadd7b1f5d2f119654f7299",
     "grade": false,
     "grade_id": "cell-158058de07eb5fd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You saw how we can fit a ridge model and make predictions for different values of `penalty`. But it would be great if you could find the \"best\" value of the penalty. This is something you can use **hyperparameter** tuning for. Hyperparameter tuning is in its simplest form a way of fitting many models with different sets of hyperparameters trying to find one that performs \"best\".\n",
    "\n",
    "The complexity in hyperparameter tuning can come from how you try different models. You will keep it simple for this lab and only look at grid search, only looking at evenly spaced parameter values. This is a fine enough approach if you have one or two tunable parameters but can become computationally infeasible. \n",
    "\n",
    "See the chapter on [iterative search](https://www.tmwr.org/iterative-search.html) from [Tidy Modeling with R](https://www.tmwr.org/) for more information.\n",
    "\n",
    "You begin like normal by setting up a validation split (testing and training set). A **K-fold cross-validation data set** is created on the training data set with 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42f53611ea556db3b2e9b78eb2d378fb",
     "grade": false,
     "grade_id": "cell-6d08b8bc39067f6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Hitters_split <- initial_split(Hitters, strata = \"Salary\")\n",
    "Hitters_train <- training(Hitters_split)\n",
    "Hitters_test <- testing(Hitters_split)\n",
    "Hitters_fold <- vfold_cv(Hitters_train, v = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "775244d4b5c566db6716da0a05a1a682",
     "grade": false,
     "grade_id": "cell-8acba92c1439ac0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can use the `tune_grid()` function to perform hyperparameter tuning using a grid search. `tune_grid()` needs 3 different things;\n",
    "\n",
    "-   a `workflow` object containing the model and preprocessor,\n",
    "-   a `rset` object containing the resamples the `workflow` should be fitted within, and\n",
    "-   a `tibble` containing the parameter values to be evaluated.\n",
    "\n",
    "Optionally a metric set of performance metrics can be supplied for evaluation. If you don't set one then a default set of performance metrics is used.\n",
    "\n",
    "You already have a resample object created in `Hitters_fold`. Now you should create the workflow specification next.\n",
    "\n",
    "You just used the data set as is when you fit the model earlier. However, **ridge regression** is scale sensitive so you need to make sure that the variables are on the same scale. You can use `step_normalize()`. Secondly you can deal with the factor variables yourself using `step_novel()` and `step_dummy()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27665ec102b0d50312641d0a5cc7c68e",
     "grade": false,
     "grade_id": "cell-beff609e86174b49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ridge_recipe <- \n",
    "  recipe(formula = Salary ~ ., data = Hitters_train) %>% \n",
    "  step_novel(all_nominal_predictors()) %>% \n",
    "  step_dummy(all_nominal_predictors()) %>% \n",
    "  step_zv(all_predictors()) %>% \n",
    "  step_normalize(all_predictors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "672190eaab0e6cd76f64d3ceac323f20",
     "grade": false,
     "grade_id": "cell-b1a2e244c10da6e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The model specification will look very similar to what you have seen earlier, but you will set `penalty = tune()`. This tells `tune_grid()` that the `penalty` parameter should be tuned. The output variable here will once again be `ridge_spec`. The functions used will be `linear_reg`, `set_mode` and `set_engine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8957910ebb460efb6bbb8cbd48d832fe",
     "grade": false,
     "grade_id": "cell-e4154b703955e266",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here \n",
    "ridge_spec <- linear_reg(penalty = tune(), mixture = 1) %>% \n",
    "  set_mode(\"regression\") %>% \n",
    "  set_engine(\"glmnet\") \n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f90c671d4673dfb3796ef8b0a746a0ca",
     "grade": true,
     "grade_id": "cell-b62b731e980596be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3c3e0b9b4ea0979b4159a12712e6bc2",
     "grade": false,
     "grade_id": "cell-e14f35840089ca3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now you combine to create a `workflow` object. Your output variable here will be `ridge_worfklow` and the three functions you will use will be `workflow`,`add_recipe` and `add_model`. Your recipe will be `ridge_recipe` and your model will be `ridge_spec`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "781a0d9843639e353c1317f7f686ace2",
     "grade": false,
     "grade_id": "cell-d46a34102747835b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here \n",
    "ridge_workflow <- workflow() %>% \n",
    "  add_recipe(ridge_recipe) %>% \n",
    "  add_model(ridge_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "215ca8f20c7b53ba1cbbbb5b4a762b6c",
     "grade": true,
     "grade_id": "cell-b73c60b90f03a803",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03504be2e1f1573b27b62a552822db1a",
     "grade": false,
     "grade_id": "cell-66d8b93de8ca4104",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The last thing you need is the values of `penalty` you are trying. This can be created using `grid_regular()` which creates a grid of evenly spaces parameter values. You use the `penalty()` function from the [dials](https://dials.tidymodels.org/) package to denote the parameter and set the range of the grid you are searching for. Note that this range is log-scaled. Your output variable here is going to be `penalty_grid`. For `penalty` use a range from -5 to 5, and 50 values (levels).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06061e32fe73132d55a0acafbe94ea4b",
     "grade": false,
     "grade_id": "cell-85ccc900bd385b13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>penalty</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.000000e-05</td></tr>\n",
       "\t<tr><td>1.599859e-05</td></tr>\n",
       "\t<tr><td>2.559548e-05</td></tr>\n",
       "\t<tr><td>4.094915e-05</td></tr>\n",
       "\t<tr><td>6.551286e-05</td></tr>\n",
       "\t<tr><td>1.048113e-04</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 1\n",
       "\\begin{tabular}{l}\n",
       " penalty\\\\\n",
       " <dbl>\\\\\n",
       "\\hline\n",
       "\t 1.000000e-05\\\\\n",
       "\t 1.599859e-05\\\\\n",
       "\t 2.559548e-05\\\\\n",
       "\t 4.094915e-05\\\\\n",
       "\t 6.551286e-05\\\\\n",
       "\t 1.048113e-04\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 1\n",
       "\n",
       "| penalty &lt;dbl&gt; |\n",
       "|---|\n",
       "| 1.000000e-05 |\n",
       "| 1.599859e-05 |\n",
       "| 2.559548e-05 |\n",
       "| 4.094915e-05 |\n",
       "| 6.551286e-05 |\n",
       "| 1.048113e-04 |\n",
       "\n"
      ],
      "text/plain": [
       "  penalty     \n",
       "1 1.000000e-05\n",
       "2 1.599859e-05\n",
       "3 2.559548e-05\n",
       "4 4.094915e-05\n",
       "5 6.551286e-05\n",
       "6 1.048113e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "penalty_grid <- grid_regular(penalty(range = c(-5,5), trans = log10_trans()), levels = 50)  \n",
    "\n",
    "head(penalty_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd9afdf3ac027ab39ac27d0863dc9d07",
     "grade": true,
     "grade_id": "cell-f90c48494d305cd3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in expect_equal(penalty_grid$penalty[1], 1e-05): could not find function \"expect_equal\"\n",
     "output_type": "error",
     "traceback": [
      "Error in expect_equal(penalty_grid$penalty[1], 1e-05): could not find function \"expect_equal\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "expect_equal(penalty_grid$penalty[1], 1e-05)\n",
    "expect_equal(penalty_grid$penalty[25], 0.79060432109077, tolerance=1e-5)\n",
    "expect_equal(penalty_grid$penalty[50], 1e+05)\n",
    "\n",
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4efb943e6397f7bbbf36f63298e17e22",
     "grade": false,
     "grade_id": "cell-0703997dfebdc01e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using 50 levels for one parameter might seem overkill and in many applications it is. But remember that `glmnet` fits all the models in one go so adding more levels to `penalty` doesn't affect the computational speed much.\n",
    "\n",
    "Now you have everything you need and you can fit all the models. Your output variable here is going to be `tune_res` and you will be using the `tune_grid` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42ef85e9a873e5493b95bbf6c9aea012",
     "grade": false,
     "grade_id": "cell-2b3fa7886438a45e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m!\u001b[39m \u001b[33mFold01: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold02: internal:\n",
      "  \u001b[1m\u001b[22mThere were 14 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 37: `penalty = 222.2996`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 13 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold03: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold04: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold05: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold06: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold07: internal:\n",
      "  \u001b[1m\u001b[22mThere were 14 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 37: `penalty = 222.2996`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 13 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold08: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold09: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold10: internal:\n",
      "  \u001b[1m\u001b[22mThere were 13 warnings in `dplyr::summarise()`.\n",
      "  The first warning was:\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m In argument: `.estimate = metric_fn(truth = Salar...\n",
      "    na_rm)`.\n",
      "  \u001b[36mℹ\u001b[33m In group 38: `penalty = 355.648`.\n",
      "  Caused by warning:\n",
      "  \u001b[33m!\u001b[33m A correlation computation is required, but `estimate` is c...\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[33m Run `dplyr::last_dplyr_warnings()` to see the 12 ...\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tune_res <- tune_grid(\n",
    "  ridge_workflow,\n",
    "  resamples = Hitters_fold, \n",
    "  grid = penalty_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a4decdb3aadbbeab0758309fb67839a",
     "grade": false,
     "grade_id": "cell-9b165a95a6e2b639",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The output of `tune_grid()` can be hard to read by itself unprocessed. `autoplot()` creates a great visualization. Go on ahead and use this function for visualization. What do you notice in your plot? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df4618ca61cbb8841f8a7293a1f7cf5d",
     "grade": false,
     "grade_id": "cell-34aaf7586c48f4d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nFARICCkIkBBS0P8Dyb32/nb/TwoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoplot(tune_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf5dc9f77ad27eee317f7cfc8ec086d7",
     "grade": false,
     "grade_id": "cell-b807b8ed73b3dc37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can also see the raw metrics that created this chart by calling `collect_matrics()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf290a79175ef109cda0523bacb08b9b",
     "grade": false,
     "grade_id": "cell-d4388d07b349a945",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 100 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>penalty</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.000000e-05</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model01</td></tr>\n",
       "\t<tr><td>1.000000e-05</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model01</td></tr>\n",
       "\t<tr><td>1.599859e-05</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model02</td></tr>\n",
       "\t<tr><td>1.599859e-05</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model02</td></tr>\n",
       "\t<tr><td>2.559548e-05</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model03</td></tr>\n",
       "\t<tr><td>2.559548e-05</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model03</td></tr>\n",
       "\t<tr><td>4.094915e-05</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model04</td></tr>\n",
       "\t<tr><td>4.094915e-05</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model04</td></tr>\n",
       "\t<tr><td>6.551286e-05</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model05</td></tr>\n",
       "\t<tr><td>6.551286e-05</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model05</td></tr>\n",
       "\t<tr><td>1.048113e-04</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model06</td></tr>\n",
       "\t<tr><td>1.048113e-04</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model06</td></tr>\n",
       "\t<tr><td>1.676833e-04</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model07</td></tr>\n",
       "\t<tr><td>1.676833e-04</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model07</td></tr>\n",
       "\t<tr><td>2.682696e-04</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model08</td></tr>\n",
       "\t<tr><td>2.682696e-04</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model08</td></tr>\n",
       "\t<tr><td>4.291934e-04</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model09</td></tr>\n",
       "\t<tr><td>4.291934e-04</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model09</td></tr>\n",
       "\t<tr><td>6.866488e-04</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model10</td></tr>\n",
       "\t<tr><td>6.866488e-04</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model10</td></tr>\n",
       "\t<tr><td>1.098541e-03</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model11</td></tr>\n",
       "\t<tr><td>1.098541e-03</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model11</td></tr>\n",
       "\t<tr><td>1.757511e-03</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model12</td></tr>\n",
       "\t<tr><td>1.757511e-03</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model12</td></tr>\n",
       "\t<tr><td>2.811769e-03</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model13</td></tr>\n",
       "\t<tr><td>2.811769e-03</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model13</td></tr>\n",
       "\t<tr><td>4.498433e-03</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model14</td></tr>\n",
       "\t<tr><td>4.498433e-03</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model14</td></tr>\n",
       "\t<tr><td>7.196857e-03</td><td>rmse</td><td>standard</td><td>292.6114432</td><td>10</td><td>22.14329353</td><td>Preprocessor1_Model15</td></tr>\n",
       "\t<tr><td>7.196857e-03</td><td>rsq </td><td>standard</td><td>  0.4755473</td><td>10</td><td> 0.05005364</td><td>Preprocessor1_Model15</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>   138.9495</td><td>rmse</td><td>standard</td><td>336.9583896</td><td>10</td><td>26.88675940</td><td>Preprocessor1_Model36</td></tr>\n",
       "\t<tr><td>   138.9495</td><td>rsq </td><td>standard</td><td>  0.4424737</td><td>10</td><td> 0.06325793</td><td>Preprocessor1_Model36</td></tr>\n",
       "\t<tr><td>   222.2996</td><td>rmse</td><td>standard</td><td>384.4415278</td><td>10</td><td>26.69918609</td><td>Preprocessor1_Model37</td></tr>\n",
       "\t<tr><td>   222.2996</td><td>rsq </td><td>standard</td><td>  0.3823782</td><td> 8</td><td> 0.06699186</td><td>Preprocessor1_Model37</td></tr>\n",
       "\t<tr><td>   355.6480</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model38</td></tr>\n",
       "\t<tr><td>   355.6480</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model38</td></tr>\n",
       "\t<tr><td>   568.9866</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model39</td></tr>\n",
       "\t<tr><td>   568.9866</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model39</td></tr>\n",
       "\t<tr><td>   910.2982</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model40</td></tr>\n",
       "\t<tr><td>   910.2982</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model40</td></tr>\n",
       "\t<tr><td>  1456.3485</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model41</td></tr>\n",
       "\t<tr><td>  1456.3485</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model41</td></tr>\n",
       "\t<tr><td>  2329.9518</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model42</td></tr>\n",
       "\t<tr><td>  2329.9518</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model42</td></tr>\n",
       "\t<tr><td>  3727.5937</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model43</td></tr>\n",
       "\t<tr><td>  3727.5937</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model43</td></tr>\n",
       "\t<tr><td>  5963.6233</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model44</td></tr>\n",
       "\t<tr><td>  5963.6233</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model44</td></tr>\n",
       "\t<tr><td>  9540.9548</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model45</td></tr>\n",
       "\t<tr><td>  9540.9548</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model45</td></tr>\n",
       "\t<tr><td> 15264.1797</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model46</td></tr>\n",
       "\t<tr><td> 15264.1797</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model46</td></tr>\n",
       "\t<tr><td> 24420.5309</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model47</td></tr>\n",
       "\t<tr><td> 24420.5309</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model47</td></tr>\n",
       "\t<tr><td> 39069.3994</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model48</td></tr>\n",
       "\t<tr><td> 39069.3994</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model48</td></tr>\n",
       "\t<tr><td> 62505.5193</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model49</td></tr>\n",
       "\t<tr><td> 62505.5193</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model49</td></tr>\n",
       "\t<tr><td>100000.0000</td><td>rmse</td><td>standard</td><td>390.0824118</td><td>10</td><td>25.81992351</td><td>Preprocessor1_Model50</td></tr>\n",
       "\t<tr><td>100000.0000</td><td>rsq </td><td>standard</td><td>        NaN</td><td> 0</td><td>         NA</td><td>Preprocessor1_Model50</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 100 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " penalty & .metric & .estimator & mean & n & std\\_err & .config\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl> & <int> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 1.000000e-05 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model01\\\\\n",
       "\t 1.000000e-05 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model01\\\\\n",
       "\t 1.599859e-05 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model02\\\\\n",
       "\t 1.599859e-05 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model02\\\\\n",
       "\t 2.559548e-05 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model03\\\\\n",
       "\t 2.559548e-05 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model03\\\\\n",
       "\t 4.094915e-05 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model04\\\\\n",
       "\t 4.094915e-05 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model04\\\\\n",
       "\t 6.551286e-05 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model05\\\\\n",
       "\t 6.551286e-05 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model05\\\\\n",
       "\t 1.048113e-04 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model06\\\\\n",
       "\t 1.048113e-04 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model06\\\\\n",
       "\t 1.676833e-04 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model07\\\\\n",
       "\t 1.676833e-04 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model07\\\\\n",
       "\t 2.682696e-04 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model08\\\\\n",
       "\t 2.682696e-04 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model08\\\\\n",
       "\t 4.291934e-04 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model09\\\\\n",
       "\t 4.291934e-04 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model09\\\\\n",
       "\t 6.866488e-04 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model10\\\\\n",
       "\t 6.866488e-04 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model10\\\\\n",
       "\t 1.098541e-03 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model11\\\\\n",
       "\t 1.098541e-03 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model11\\\\\n",
       "\t 1.757511e-03 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model12\\\\\n",
       "\t 1.757511e-03 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model12\\\\\n",
       "\t 2.811769e-03 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model13\\\\\n",
       "\t 2.811769e-03 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model13\\\\\n",
       "\t 4.498433e-03 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model14\\\\\n",
       "\t 4.498433e-03 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model14\\\\\n",
       "\t 7.196857e-03 & rmse & standard & 292.6114432 & 10 & 22.14329353 & Preprocessor1\\_Model15\\\\\n",
       "\t 7.196857e-03 & rsq  & standard &   0.4755473 & 10 &  0.05005364 & Preprocessor1\\_Model15\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t    138.9495 & rmse & standard & 336.9583896 & 10 & 26.88675940 & Preprocessor1\\_Model36\\\\\n",
       "\t    138.9495 & rsq  & standard &   0.4424737 & 10 &  0.06325793 & Preprocessor1\\_Model36\\\\\n",
       "\t    222.2996 & rmse & standard & 384.4415278 & 10 & 26.69918609 & Preprocessor1\\_Model37\\\\\n",
       "\t    222.2996 & rsq  & standard &   0.3823782 &  8 &  0.06699186 & Preprocessor1\\_Model37\\\\\n",
       "\t    355.6480 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model38\\\\\n",
       "\t    355.6480 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model38\\\\\n",
       "\t    568.9866 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model39\\\\\n",
       "\t    568.9866 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model39\\\\\n",
       "\t    910.2982 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model40\\\\\n",
       "\t    910.2982 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model40\\\\\n",
       "\t   1456.3485 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model41\\\\\n",
       "\t   1456.3485 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model41\\\\\n",
       "\t   2329.9518 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model42\\\\\n",
       "\t   2329.9518 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model42\\\\\n",
       "\t   3727.5937 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model43\\\\\n",
       "\t   3727.5937 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model43\\\\\n",
       "\t   5963.6233 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model44\\\\\n",
       "\t   5963.6233 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model44\\\\\n",
       "\t   9540.9548 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model45\\\\\n",
       "\t   9540.9548 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model45\\\\\n",
       "\t  15264.1797 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model46\\\\\n",
       "\t  15264.1797 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model46\\\\\n",
       "\t  24420.5309 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model47\\\\\n",
       "\t  24420.5309 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model47\\\\\n",
       "\t  39069.3994 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model48\\\\\n",
       "\t  39069.3994 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model48\\\\\n",
       "\t  62505.5193 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model49\\\\\n",
       "\t  62505.5193 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model49\\\\\n",
       "\t 100000.0000 & rmse & standard & 390.0824118 & 10 & 25.81992351 & Preprocessor1\\_Model50\\\\\n",
       "\t 100000.0000 & rsq  & standard &         NaN &  0 &          NA & Preprocessor1\\_Model50\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 100 × 7\n",
       "\n",
       "| penalty &lt;dbl&gt; | .metric &lt;chr&gt; | .estimator &lt;chr&gt; | mean &lt;dbl&gt; | n &lt;int&gt; | std_err &lt;dbl&gt; | .config &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1.000000e-05 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model01 |\n",
       "| 1.000000e-05 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model01 |\n",
       "| 1.599859e-05 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model02 |\n",
       "| 1.599859e-05 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model02 |\n",
       "| 2.559548e-05 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model03 |\n",
       "| 2.559548e-05 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model03 |\n",
       "| 4.094915e-05 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model04 |\n",
       "| 4.094915e-05 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model04 |\n",
       "| 6.551286e-05 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model05 |\n",
       "| 6.551286e-05 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model05 |\n",
       "| 1.048113e-04 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model06 |\n",
       "| 1.048113e-04 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model06 |\n",
       "| 1.676833e-04 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model07 |\n",
       "| 1.676833e-04 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model07 |\n",
       "| 2.682696e-04 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model08 |\n",
       "| 2.682696e-04 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model08 |\n",
       "| 4.291934e-04 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model09 |\n",
       "| 4.291934e-04 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model09 |\n",
       "| 6.866488e-04 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model10 |\n",
       "| 6.866488e-04 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model10 |\n",
       "| 1.098541e-03 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model11 |\n",
       "| 1.098541e-03 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model11 |\n",
       "| 1.757511e-03 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model12 |\n",
       "| 1.757511e-03 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model12 |\n",
       "| 2.811769e-03 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model13 |\n",
       "| 2.811769e-03 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model13 |\n",
       "| 4.498433e-03 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model14 |\n",
       "| 4.498433e-03 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model14 |\n",
       "| 7.196857e-03 | rmse | standard | 292.6114432 | 10 | 22.14329353 | Preprocessor1_Model15 |\n",
       "| 7.196857e-03 | rsq  | standard |   0.4755473 | 10 |  0.05005364 | Preprocessor1_Model15 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "|    138.9495 | rmse | standard | 336.9583896 | 10 | 26.88675940 | Preprocessor1_Model36 |\n",
       "|    138.9495 | rsq  | standard |   0.4424737 | 10 |  0.06325793 | Preprocessor1_Model36 |\n",
       "|    222.2996 | rmse | standard | 384.4415278 | 10 | 26.69918609 | Preprocessor1_Model37 |\n",
       "|    222.2996 | rsq  | standard |   0.3823782 |  8 |  0.06699186 | Preprocessor1_Model37 |\n",
       "|    355.6480 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model38 |\n",
       "|    355.6480 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model38 |\n",
       "|    568.9866 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model39 |\n",
       "|    568.9866 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model39 |\n",
       "|    910.2982 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model40 |\n",
       "|    910.2982 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model40 |\n",
       "|   1456.3485 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model41 |\n",
       "|   1456.3485 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model41 |\n",
       "|   2329.9518 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model42 |\n",
       "|   2329.9518 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model42 |\n",
       "|   3727.5937 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model43 |\n",
       "|   3727.5937 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model43 |\n",
       "|   5963.6233 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model44 |\n",
       "|   5963.6233 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model44 |\n",
       "|   9540.9548 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model45 |\n",
       "|   9540.9548 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model45 |\n",
       "|  15264.1797 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model46 |\n",
       "|  15264.1797 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model46 |\n",
       "|  24420.5309 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model47 |\n",
       "|  24420.5309 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model47 |\n",
       "|  39069.3994 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model48 |\n",
       "|  39069.3994 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model48 |\n",
       "|  62505.5193 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model49 |\n",
       "|  62505.5193 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model49 |\n",
       "| 100000.0000 | rmse | standard | 390.0824118 | 10 | 25.81992351 | Preprocessor1_Model50 |\n",
       "| 100000.0000 | rsq  | standard |         NaN |  0 |          NA | Preprocessor1_Model50 |\n",
       "\n"
      ],
      "text/plain": [
       "    penalty      .metric .estimator mean        n  std_err    \n",
       "1   1.000000e-05 rmse    standard   292.6114432 10 22.14329353\n",
       "2   1.000000e-05 rsq     standard     0.4755473 10  0.05005364\n",
       "3   1.599859e-05 rmse    standard   292.6114432 10 22.14329353\n",
       "4   1.599859e-05 rsq     standard     0.4755473 10  0.05005364\n",
       "5   2.559548e-05 rmse    standard   292.6114432 10 22.14329353\n",
       "6   2.559548e-05 rsq     standard     0.4755473 10  0.05005364\n",
       "7   4.094915e-05 rmse    standard   292.6114432 10 22.14329353\n",
       "8   4.094915e-05 rsq     standard     0.4755473 10  0.05005364\n",
       "9   6.551286e-05 rmse    standard   292.6114432 10 22.14329353\n",
       "10  6.551286e-05 rsq     standard     0.4755473 10  0.05005364\n",
       "11  1.048113e-04 rmse    standard   292.6114432 10 22.14329353\n",
       "12  1.048113e-04 rsq     standard     0.4755473 10  0.05005364\n",
       "13  1.676833e-04 rmse    standard   292.6114432 10 22.14329353\n",
       "14  1.676833e-04 rsq     standard     0.4755473 10  0.05005364\n",
       "15  2.682696e-04 rmse    standard   292.6114432 10 22.14329353\n",
       "16  2.682696e-04 rsq     standard     0.4755473 10  0.05005364\n",
       "17  4.291934e-04 rmse    standard   292.6114432 10 22.14329353\n",
       "18  4.291934e-04 rsq     standard     0.4755473 10  0.05005364\n",
       "19  6.866488e-04 rmse    standard   292.6114432 10 22.14329353\n",
       "20  6.866488e-04 rsq     standard     0.4755473 10  0.05005364\n",
       "21  1.098541e-03 rmse    standard   292.6114432 10 22.14329353\n",
       "22  1.098541e-03 rsq     standard     0.4755473 10  0.05005364\n",
       "23  1.757511e-03 rmse    standard   292.6114432 10 22.14329353\n",
       "24  1.757511e-03 rsq     standard     0.4755473 10  0.05005364\n",
       "25  2.811769e-03 rmse    standard   292.6114432 10 22.14329353\n",
       "26  2.811769e-03 rsq     standard     0.4755473 10  0.05005364\n",
       "27  4.498433e-03 rmse    standard   292.6114432 10 22.14329353\n",
       "28  4.498433e-03 rsq     standard     0.4755473 10  0.05005364\n",
       "29  7.196857e-03 rmse    standard   292.6114432 10 22.14329353\n",
       "30  7.196857e-03 rsq     standard     0.4755473 10  0.05005364\n",
       "⋮   ⋮            ⋮       ⋮          ⋮           ⋮  ⋮          \n",
       "71     138.9495  rmse    standard   336.9583896 10 26.88675940\n",
       "72     138.9495  rsq     standard     0.4424737 10  0.06325793\n",
       "73     222.2996  rmse    standard   384.4415278 10 26.69918609\n",
       "74     222.2996  rsq     standard     0.3823782  8  0.06699186\n",
       "75     355.6480  rmse    standard   390.0824118 10 25.81992351\n",
       "76     355.6480  rsq     standard           NaN  0          NA\n",
       "77     568.9866  rmse    standard   390.0824118 10 25.81992351\n",
       "78     568.9866  rsq     standard           NaN  0          NA\n",
       "79     910.2982  rmse    standard   390.0824118 10 25.81992351\n",
       "80     910.2982  rsq     standard           NaN  0          NA\n",
       "81    1456.3485  rmse    standard   390.0824118 10 25.81992351\n",
       "82    1456.3485  rsq     standard           NaN  0          NA\n",
       "83    2329.9518  rmse    standard   390.0824118 10 25.81992351\n",
       "84    2329.9518  rsq     standard           NaN  0          NA\n",
       "85    3727.5937  rmse    standard   390.0824118 10 25.81992351\n",
       "86    3727.5937  rsq     standard           NaN  0          NA\n",
       "87    5963.6233  rmse    standard   390.0824118 10 25.81992351\n",
       "88    5963.6233  rsq     standard           NaN  0          NA\n",
       "89    9540.9548  rmse    standard   390.0824118 10 25.81992351\n",
       "90    9540.9548  rsq     standard           NaN  0          NA\n",
       "91   15264.1797  rmse    standard   390.0824118 10 25.81992351\n",
       "92   15264.1797  rsq     standard           NaN  0          NA\n",
       "93   24420.5309  rmse    standard   390.0824118 10 25.81992351\n",
       "94   24420.5309  rsq     standard           NaN  0          NA\n",
       "95   39069.3994  rmse    standard   390.0824118 10 25.81992351\n",
       "96   39069.3994  rsq     standard           NaN  0          NA\n",
       "97   62505.5193  rmse    standard   390.0824118 10 25.81992351\n",
       "98   62505.5193  rsq     standard           NaN  0          NA\n",
       "99  100000.0000  rmse    standard   390.0824118 10 25.81992351\n",
       "100 100000.0000  rsq     standard           NaN  0          NA\n",
       "    .config              \n",
       "1   Preprocessor1_Model01\n",
       "2   Preprocessor1_Model01\n",
       "3   Preprocessor1_Model02\n",
       "4   Preprocessor1_Model02\n",
       "5   Preprocessor1_Model03\n",
       "6   Preprocessor1_Model03\n",
       "7   Preprocessor1_Model04\n",
       "8   Preprocessor1_Model04\n",
       "9   Preprocessor1_Model05\n",
       "10  Preprocessor1_Model05\n",
       "11  Preprocessor1_Model06\n",
       "12  Preprocessor1_Model06\n",
       "13  Preprocessor1_Model07\n",
       "14  Preprocessor1_Model07\n",
       "15  Preprocessor1_Model08\n",
       "16  Preprocessor1_Model08\n",
       "17  Preprocessor1_Model09\n",
       "18  Preprocessor1_Model09\n",
       "19  Preprocessor1_Model10\n",
       "20  Preprocessor1_Model10\n",
       "21  Preprocessor1_Model11\n",
       "22  Preprocessor1_Model11\n",
       "23  Preprocessor1_Model12\n",
       "24  Preprocessor1_Model12\n",
       "25  Preprocessor1_Model13\n",
       "26  Preprocessor1_Model13\n",
       "27  Preprocessor1_Model14\n",
       "28  Preprocessor1_Model14\n",
       "29  Preprocessor1_Model15\n",
       "30  Preprocessor1_Model15\n",
       "⋮   ⋮                    \n",
       "71  Preprocessor1_Model36\n",
       "72  Preprocessor1_Model36\n",
       "73  Preprocessor1_Model37\n",
       "74  Preprocessor1_Model37\n",
       "75  Preprocessor1_Model38\n",
       "76  Preprocessor1_Model38\n",
       "77  Preprocessor1_Model39\n",
       "78  Preprocessor1_Model39\n",
       "79  Preprocessor1_Model40\n",
       "80  Preprocessor1_Model40\n",
       "81  Preprocessor1_Model41\n",
       "82  Preprocessor1_Model41\n",
       "83  Preprocessor1_Model42\n",
       "84  Preprocessor1_Model42\n",
       "85  Preprocessor1_Model43\n",
       "86  Preprocessor1_Model43\n",
       "87  Preprocessor1_Model44\n",
       "88  Preprocessor1_Model44\n",
       "89  Preprocessor1_Model45\n",
       "90  Preprocessor1_Model45\n",
       "91  Preprocessor1_Model46\n",
       "92  Preprocessor1_Model46\n",
       "93  Preprocessor1_Model47\n",
       "94  Preprocessor1_Model47\n",
       "95  Preprocessor1_Model48\n",
       "96  Preprocessor1_Model48\n",
       "97  Preprocessor1_Model49\n",
       "98  Preprocessor1_Model49\n",
       "99  Preprocessor1_Model50\n",
       "100 Preprocessor1_Model50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collect_metrics(tune_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fe9b410a6006a6c711a5a3603ae1563",
     "grade": false,
     "grade_id": "cell-68bad29f91a09bff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The \"best\" values of this can be selected using `select_best()`, this function requires you to specify a `metric` that it should select against; use \"rsq\" for your metric. Your output variable here will be `best_penalty`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "808d99464fe46e7576330cf73746d4d1",
     "grade": false,
     "grade_id": "cell-0d6f842a8625f495",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>penalty</th><th scope=col>.config</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.179475</td><td>Preprocessor1_Model29</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " penalty & .config\\\\\n",
       " <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 5.179475 & Preprocessor1\\_Model29\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 2\n",
       "\n",
       "| penalty &lt;dbl&gt; | .config &lt;fct&gt; |\n",
       "|---|---|\n",
       "| 5.179475 | Preprocessor1_Model29 |\n",
       "\n"
      ],
      "text/plain": [
       "  penalty  .config              \n",
       "1 5.179475 Preprocessor1_Model29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "best_penalty <- select_best(tune_res ,metric = 'rsq')\n",
    "\n",
    "best_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7995ed0b89c143623420d6046e44fe41",
     "grade": true,
     "grade_id": "cell-2f357988b2a8bef2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24be51b909e1d15e702220cba9289be1",
     "grade": false,
     "grade_id": "cell-42a1716bb67ef782",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This value of `penalty` can then be used with `finalize_workflow()` to update/finalize the recipe by replacing `tune()` with the value of `best_penalty`. Now, this model should be fit again, this time using the whole training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c42304832dbed7a7b9ba65b8ee98ab2c",
     "grade": false,
     "grade_id": "cell-6d1962a650b51696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ridge_final <- finalize_workflow(ridge_workflow, best_penalty)\n",
    "ridge_final_fit <- fit(ridge_final, data = Hitters_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1383aacf17ef44c256607d4bc6801da",
     "grade": false,
     "grade_id": "cell-30f6ab7fc317da04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This final model can now be applied on your testing data set to validate the performance. Go ahead and perfrom this task. You will use both the`augment` and the `rsq` function. What do you notice? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de418ebf46b2125c254a20eb9e02115e",
     "grade": false,
     "grade_id": "cell-a5696e0de0063018",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>rsq</td><td>standard</td><td>0.4006274</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & .estimator & .estimate\\\\\n",
       " <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t rsq & standard & 0.4006274\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 3\n",
       "\n",
       "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| rsq | standard | 0.4006274 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric .estimator .estimate\n",
       "1 rsq     standard   0.4006274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augment(ridge_final_fit, new_data = Hitters_test) %>%\n",
    "  rsq(truth = Salary, estimate = .pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
